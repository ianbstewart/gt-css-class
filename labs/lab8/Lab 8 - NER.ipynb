{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Named entity recognition\n",
    "\n",
    "- Jacob Eisenstein\n",
    "- For Georgia Tech CS8803-CSS, Fall 2017\n",
    "\n",
    "In this project, you'll use Stanford's CoreNLP tagger to tag names of people, places, and organizations in the abolitionist newspaper The Liberator.\n",
    "\n",
    "You can download the software here:\n",
    "\n",
    "https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "\n",
    "Next, unzip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open stanford-ner-2017-06-09.zip, stanford-ner-2017-06-09.zip.zip or stanford-ner-2017-06-09.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "! unzip stanford-ner-2017-06-09.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from glob import glob\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a tagger object. The first argument is the location of the model file, the second argument is the location of the jar file. Both should have been extracted from the zipfile you downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.local/lib/python3.5/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tagger = StanfordNERTagger('stanford-ner-2017-06-09/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "                           path_to_jar='stanford-ner-2017-06-09/stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it. The input is a sequence of tokens. Here we'll just use string split for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = 'Colonel Mustard was in Druid Hills , with the President of the Coca Cola Corporation .'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colonel', 'O'),\n",
       " ('Mustard', 'PERSON'),\n",
       " ('was', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Druid', 'LOCATION'),\n",
       " ('Hills', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('President', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Coca', 'ORGANIZATION'),\n",
       " ('Cola', 'ORGANIZATION'),\n",
       " ('Corporation', 'ORGANIZATION'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a labeling of each token. The tag 'O' means 'outside' of any entity name.\n",
    "\n",
    "Here is a simple function that extracts names from this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entities(tagger_output):\n",
    "    current_entity = []\n",
    "    entities = []\n",
    "    for token,tag in tagger_output:\n",
    "        if tag != 'O':\n",
    "            current_entity.append((token,tag))\n",
    "        else:\n",
    "            if current_entity != []:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "    return ['%s_%s'%(' '.join([tok for tok,tag in entity]),entity[0][1]) for entity in entities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mustard_PERSON',\n",
       " 'Druid Hills_LOCATION',\n",
       " 'Coca Cola Corporation_ORGANIZATION']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a harder one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_example = 'I told Lucia Coca Cola was bad for her teeth .'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'O'),\n",
       " ('told', 'O'),\n",
       " ('Lucia', 'ORGANIZATION'),\n",
       " ('Coca', 'ORGANIZATION'),\n",
       " ('Cola', 'ORGANIZATION'),\n",
       " ('was', 'O'),\n",
       " ('bad', 'O'),\n",
       " ('for', 'O'),\n",
       " ('her', 'O'),\n",
       " ('teeth', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(hard_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucia Coca Cola_ORGANIZATION']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(hard_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with_complementizer = 'I told Lucia that Coca Cola was bad for her teeth .'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucia_ORGANIZATION', 'Coca Cola_ORGANIZATION']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(with_complementizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is why you should use complementizers when you write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging full documents\n",
    "\n",
    "To do better word segmentation, make sure you have downloaded the `punkt` tokenization model from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jacob/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try tagging a document from The Liberator.\n",
    "\n",
    "Link or copy this directory in from Lab 7 if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ln -s ../lab7/liberator-stories/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'liberator-stories/Issue of April 01, 1853/story006.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_lines = []\n",
    "with open(filename) as fin:\n",
    "    for line in fin:\n",
    "        tagged_lines.append(tagger.tag(word_tokenize(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Southern', 'MISC'), ('slaveholders', 'O'), ('have', 'O'), ('a', 'O'), ('passion', 'O'), ('for', 'O'), ('mischiefframed', 'O'), ('into', 'O'), ('law', 'O'), (',', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_lines[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Southern_MISC',\n",
       " 'North_LOCATION',\n",
       " 'Illinois_LOCATION',\n",
       " 'Virginia_LOCATION',\n",
       " 'Old Dominion_MISC',\n",
       " 'Illinoisan_LOCATION',\n",
       " 'Virginia_LOCATION',\n",
       " 'Illinois_LOCATION',\n",
       " 'Northern_ORGANIZATION',\n",
       " 'question-In_MISC',\n",
       " 'Democracy_ORGANIZATION',\n",
       " 'Commonwealth_ORGANIZATION']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagged_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn**: Get a story from today's news, copy it into the variable below, and extract the named entities. Skim the first few lines of the story yourself to see if it's correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "your_story = \"\"\"\n",
    "paste here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa_LOCATION',\n",
       " 'Trump_PERSON',\n",
       " 'David T. Johnson_PERSON',\n",
       " 'Cowanda Jones-Johnson_PERSON',\n",
       " 'The Washington Post_ORGANIZATION',\n",
       " 'White House_LOCATION',\n",
       " 'Johnson_PERSON',\n",
       " 'Myeshia Johnson_PERSON',\n",
       " 'Johnson_PERSON',\n",
       " 'Frederica S. Wilson_PERSON',\n",
       " 'Trump_PERSON',\n",
       " 'Johnson_PERSON',\n",
       " 'Trump_PERSON',\n",
       " 'Trump_PERSON',\n",
       " 'Wilson_PERSON',\n",
       " 'Wilson_PERSON',\n",
       " 'Trump_PERSON']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's my output\n",
    "get_entities(tagger.tag(word_tokenize(your_story)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting entities\n",
    "\n",
    "We can keep count of all these different entities, using a `Counter` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Commonwealth_ORGANIZATION': 1,\n",
       "         'Democracy_ORGANIZATION': 1,\n",
       "         'Illinois_LOCATION': 2,\n",
       "         'Illinoisan_LOCATION': 1,\n",
       "         'North_LOCATION': 1,\n",
       "         'Northern_ORGANIZATION': 1,\n",
       "         'Old Dominion_MISC': 1,\n",
       "         'Southern_MISC': 1,\n",
       "         'Virginia_LOCATION': 2,\n",
       "         'question-In_MISC': 1})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(get_entities(tagged_lines[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cool thing about counters is that you can add them up, which makes it easy to keep a running count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter1 = Counter(get_entities(tagged_lines[0]))\n",
    "counter1 += Counter(get_entities(tagged_lines[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Commonwealth_ORGANIZATION': 2,\n",
       "         'Democracy_ORGANIZATION': 2,\n",
       "         'Illinois_LOCATION': 4,\n",
       "         'Illinoisan_LOCATION': 2,\n",
       "         'North_LOCATION': 2,\n",
       "         'Northern_ORGANIZATION': 2,\n",
       "         'Old Dominion_MISC': 2,\n",
       "         'Southern_MISC': 2,\n",
       "         'Virginia_LOCATION': 4,\n",
       "         'question-In_MISC': 2})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to incrementally build a counter as we process all stories in a single edition.\n",
    "\n",
    "Another useful trick is to build a counter from a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_list = ['a','b','a','a','c','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3, 'b': 2, 'c': 1})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(the_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** \n",
    "\n",
    "- Count the number of times a person is mentioned in your news story.\n",
    "- Count the total number of different person names that are mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing entities across multiple texts\n",
    "\n",
    "Now let's compare the named entities that are mentioned in two specific editions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edition1 = 'liberator-stories/Issue of November 01, 1850'\n",
    "edition2 = 'liberator-stories/Issue of November 11, 1859'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to compute a running count of entities across the lines and stories of an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_counts(directory,show_progress=False):\n",
    "    entity_counts = Counter()\n",
    "    for filename in glob(os.path.join(directory,'story*txt')):\n",
    "        with open (filename) as fin:\n",
    "            if show_progress: print(filename)\n",
    "            for i,line in enumerate(fin):\n",
    "                if len(line)>10:\n",
    "                    output = tagger.tag(word_tokenize(line))\n",
    "                    entity_counts += Counter(get_entities(output))\n",
    "    return entity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberator-stories/Issue of November 01, 1850/story007.txt\n",
      "liberator-stories/Issue of November 01, 1850/story000.txt\n",
      "liberator-stories/Issue of November 01, 1850/story002.txt\n",
      "liberator-stories/Issue of November 01, 1850/story003.txt\n",
      "liberator-stories/Issue of November 01, 1850/story006.txt\n",
      "liberator-stories/Issue of November 01, 1850/story001.txt\n",
      "liberator-stories/Issue of November 01, 1850/story004.txt\n",
      "liberator-stories/Issue of November 01, 1850/story005.txt\n",
      "liberator-stories/Issue of November 01, 1850/story009.txt\n",
      "liberator-stories/Issue of November 01, 1850/story008.txt\n"
     ]
    }
   ],
   "source": [
    "counts1 = get_entity_counts(edition1,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberator-stories/Issue of November 11, 1859/story007.txt\n",
      "liberator-stories/Issue of November 11, 1859/story000.txt\n",
      "liberator-stories/Issue of November 11, 1859/story002.txt\n",
      "liberator-stories/Issue of November 11, 1859/story003.txt\n",
      "liberator-stories/Issue of November 11, 1859/story006.txt\n",
      "liberator-stories/Issue of November 11, 1859/story001.txt\n",
      "liberator-stories/Issue of November 11, 1859/story004.txt\n",
      "liberator-stories/Issue of November 11, 1859/story005.txt\n",
      "liberator-stories/Issue of November 11, 1859/story009.txt\n",
      "liberator-stories/Issue of November 11, 1859/story008.txt\n"
     ]
    }
   ],
   "source": [
    "counts2 = get_entity_counts(edition2,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Massachusetts_LOCATION', 14),\n",
       " ('Constitution_ORGANIZATION', 13),\n",
       " ('United States_LOCATION', 9),\n",
       " ('Senate_ORGANIZATION', 9),\n",
       " ('God_PERSON', 7),\n",
       " ('California_LOCATION', 6),\n",
       " ('Whittier_LOCATION', 6),\n",
       " ('ERRIEN_ORGANIZATION', 6),\n",
       " ('BERRIEN_ORGANIZATION', 6),\n",
       " ('North_LOCATION', 5)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harper_PERSON', 13),\n",
       " ('Brown_PERSON', 12),\n",
       " ('North_LOCATION', 11),\n",
       " ('South_LOCATION', 9),\n",
       " ('Phillips_PERSON', 9),\n",
       " ('Virginia_LOCATION', 8),\n",
       " ('Republican_MISC', 7),\n",
       " ('Seward_PERSON', 6),\n",
       " ('Beecher_PERSON', 4),\n",
       " ('Giddings_ORGANIZATION', 4)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts2.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the John Brown's raid of Harper's Ferry dominates the news in late 1859, even though the NER system mistakenly label \"Harper\" as a person. Another key difference is \"North\" and \"South\" seem to play a bigger role in the 1859 data, which might make sense, as the war in only a year and a half away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Your turn** What are the ten most frequently-mentioned organizations, across **both** newspaper issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Constitution_ORGANIZATION', 14),\n",
       " ('Senate_ORGANIZATION', 9),\n",
       " ('ERRIEN_ORGANIZATION', 6),\n",
       " ('BERRIEN_ORGANIZATION', 6),\n",
       " ('Congress_ORGANIZATION', 6),\n",
       " ('Fugitive Slave Bill_ORGANIZATION', 5),\n",
       " ('Giddings_ORGANIZATION', 4),\n",
       " ('Supreme Court_ORGANIZATION', 4),\n",
       " ('Union_ORGANIZATION', 4),\n",
       " ('Legislature_ORGANIZATION', 3)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-scale comparison\n",
    "\n",
    "Now let's do a large-scale comparison over the years of the dataset. Because the NER system is a little slow, I ran it overnight on our server. You can load in the output as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tar xzf liberator-nes.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States_LOCATION\n",
      "States_LOCATION\n",
      "SWERED_ORGANIZATION\n",
      "Unioncan_LOCATION\n",
      "States_LOCATION\n",
      "ONSTITUTION_ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "with open('TheLiberator/Issue of April 15, 1859/story001.ne') as fin:\n",
    "    for line in fin:\n",
    "        print (line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** Read this same file into a counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build counters for all stories in a year. The following function should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_files_for_year = lambda year : glob('TheLiberator/Issue*%d/story*.ne'%(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TheLiberator/Issue of November 05, 1852/story041.ne',\n",
       " 'TheLiberator/Issue of November 05, 1852/story006.ne',\n",
       " 'TheLiberator/Issue of November 05, 1852/story032.ne',\n",
       " 'TheLiberator/Issue of November 05, 1852/story020.ne',\n",
       " 'TheLiberator/Issue of November 05, 1852/story048.ne']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files_for_year(1852)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** Implement the following function, which should return a counter of entity names for all stories in a given year. Don't forget the two tricks about Counters that I showed you above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_counts_for_year(year):\n",
    "    counts = Counter()\n",
    "    # add code here\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Massachusetts_LOCATION', 150),\n",
       " ('God_PERSON', 136),\n",
       " ('Boston_LOCATION', 127),\n",
       " ('South_LOCATION', 77),\n",
       " ('Brown_PERSON', 76),\n",
       " ('United States_LOCATION', 70),\n",
       " ('Constitution_ORGANIZATION', 68),\n",
       " ('North_LOCATION', 66),\n",
       " ('New York_LOCATION', 62),\n",
       " ('Oregon_LOCATION', 58)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_counts_for_year(1859).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the top entities for every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846: American God Alliance Rev United States Christian America England Boston Massachusetts\n",
      "1847: God American Mexico Boston United States Christian Douglass England Union South\n",
      "1848: God South North Senate Boston Union Congress American House United States\n",
      "1849: God South Boston American Congress Christian New York North United States Southern\n",
      "1850: God South Boston Webster North Congress United States Massachusetts Union Senate\n",
      "1851: God American Boston America England United States Union Constitution States North\n",
      "1852: God Boston American South Constitution New York America Pierce Washington Parker\n",
      "1853: God Boston Mann American Constitution United States Christian Massachusetts England New York\n",
      "1854: God Boston Congress American South United States Constitution Ohio North States\n",
      "1855: God Union South American North Constitution Boston United States Massachusetts New York\n",
      "1856: Kansas God South Boston North United States Union American Massachusetts New York\n",
      "1857: God South Boston North Kansas Convention American Christian Constitution New York\n",
      "1858: God Massachusetts Boston S.A. Allen Constitution South United States Legislature REV Union\n",
      "1859: Massachusetts God Boston South Brown United States Constitution North New York Oregon\n",
      "1860: God Boston Rev Constitution New York Sumner Republican United States American Parker\n",
      "1861: North God South Union Boston States Massachusetts Constitution Southern New York\n",
      "1862: God South North Union Boston Massachusetts Washington States Congress United States\n",
      "1863: God North South Boston England United States Hinna America American Union\n",
      "1864: Lincoln North God Union South Congress American Boston United States England\n",
      "1865: South God United States North States Congress Southern Union Washington American\n"
     ]
    }
   ],
   "source": [
    "for year in range(1846,1866):\n",
    "    print(year,end=': ')\n",
    "    print(' '.join([name.split('_')[0] \n",
    "                    for name,count \n",
    "                    in get_entity_counts_for_year(year).most_common(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise mutual information \n",
    "\n",
    "The top named appear to be dominated by a few recurring items: God, American, South, etc.\n",
    "\n",
    "Remember that we addressed this problem before by using pointwise mutual information (PMI). As a reminder, here is the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{PMI}(i,j) = \\log \\frac{P(i,j)}{P(i)P(j)} = \\log \\frac{P(i \\mid j) P(j)}{P(i) P(j)} = \\log P(i \\mid j) - \\log P(i)\n",
    "\\end{equation}\n",
    "\n",
    "We can compute this directly from the Counter objects. First let's compute the bottom term, $\\log P(i)$, which is the probability of each entity name, over all years in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_counts = Counter()\n",
    "for year in range(1846,1866):\n",
    "    total_counts += get_entity_counts_for_year(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # we need this for log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pi = {name:np.log(count) for name,count in total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', 7.9069154886785871),\n",
       " ('South_LOCATION', 7.4442486494967053),\n",
       " ('Boston_LOCATION', 7.4193805829186923),\n",
       " ('North_LOCATION', 7.2640301428995295),\n",
       " ('American_MISC', 7.1808311990445555)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,log_pi[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the log counts. Note that they are positive -- this means that they can't be log probabilities! $(p(x) <= 1 \\Leftrightarrow \\log p(x) <= 0)$. \n",
    "\n",
    "We'll fix this by subtracting $\\log N$, where $N$ is the sum of all counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_log_N = np.log(sum(total_counts.values()))\n",
    "log_pi = {name:np.log(count) - tot_log_N\n",
    "          for name,count in total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -3.9701877038264808),\n",
       " ('South_LOCATION', -4.4328545430083626),\n",
       " ('Boston_LOCATION', -4.4577226095863756),\n",
       " ('North_LOCATION', -4.6130730496055383),\n",
       " ('American_MISC', -4.6962719934605124)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,log_pi[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000010483"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exps of log probabilities should sum to one\n",
    "sum(np.exp(val) for val in log_pi.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! \n",
    "\n",
    "Now, to compute $\\log P(i \\mid j)$, you just need to do the same operation, but with the counter for each specific year.\n",
    "\n",
    "**Your turn**: fill in the function below, which should return a dict of names and log probabilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_log_pij(year):\n",
    "    counts = get_entity_counts_for_year(year)\n",
    "    # your code here\n",
    "    return #something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -4.2038142706300592),\n",
       " ('South_LOCATION', -4.7726637345124274),\n",
       " ('Boston_LOCATION', -4.2722820699075204),\n",
       " ('North_LOCATION', -4.9268144143396864),\n",
       " ('American_MISC', -5.0560261458196925)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desired output\n",
    "[(name,get_log_pij(1859)[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999992628"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the probabilities still sum to one\n",
    "sum(np.exp(val) for val in get_log_pij(1859).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the PMI. Note that we need only compute PMI for names the appear in the year; it's undefined $(\\log 0)$ for other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_PMI(year):\n",
    "    log_pij = get_log_pij(year)\n",
    "    pmi = {name:log_pij_name- log_pi[name] \n",
    "           for name,log_pij_name \n",
    "           in log_pij.items()}           \n",
    "    return pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -0.22630052671150569),\n",
       " ('South_LOCATION', -0.32690578666815728),\n",
       " ('Boston_LOCATION', 0.19328371713988091),\n",
       " ('North_LOCATION', -0.2987034873696075),\n",
       " ('American_MISC', -0.34265971899987946)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,get_PMI(1859)[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top names by PMI per year\n",
    "\n",
    "Now we'll call your function to get the top names by PMI for each year. \n",
    "\n",
    "We'll focus on names among the 500 most common overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top1k = [name for name,count in tot_counts.most_common(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846 Stephen C. Phillips\tNational Anti-SlaveryStandard\tBingham\tRio Grande\tHabeas Corpus\n",
      "1847 HORN\tDouglass\tFrederick\tRichmond Enquirer\tEssex\n",
      "1848 Berrien\tCorwin\tSoutherner\tRio Grande\tHale\n",
      "1849 Cooke\tAssembly\tSouthern\tWashington Union\tEssex\n",
      "1850 James Hamlet\tSlave Trade Bill\tLegislature of the State\tHaynau\tBerrien\n",
      "1851 Fugitive SlaveBill\tThis Committee\tDuncan\tFugitive Slave\tFugitive Slave Law\n",
      "1852 Hungary\tFugitive SlaveLaw\tSupreme Court of the UnitedStates\tEssex\tN.Y. Express\n",
      "1853 Robespierre\tHORACE MANN\tHaynau\tHorace Mann\tIdo\n",
      "1854 Atchinson\tSurrey\tLikethe\tBoston Daily Advertiser\tCourt House\n",
      "1855 OUGLAS\tRichmond Enquirer\tFugitive SlaveBill\tSlave Bill\tBurns\n",
      "1856 North Fifth\tChicago Press\tFrederick ( Md\tBuffalo Express\tThisquestion\n",
      "1857 Charles F. Adams\tILLIAM LLERY HANNING\tStephens\tLikethe\tState of Virginia\n",
      "1858 Abolitionistsof\tState Constitutions\tSlaverywill\tGospel of Christ\tCharleston Courier\n",
      "1859 Ifit\tBrewster\tWENDELLPHILLIPS\tArsenal\tJohn Brown\n",
      "1860 Statelaws\tWILLIAM ELLERY CHANNING\tSanborn\tAbolition\tWENDELLPHILLIPS\n",
      "1861 Northerner\tNorthernpeople\tWilliam H.Seward\tHour\tLedyard\n",
      "1862 EWING\tChandler\tPotomac\tRepublicanpress\tSecretary of War\n",
      "1863 OUGLAS\tDAVIS\tNew York Journal of Commerce\tBingham\tAVIS\n",
      "1864 Messrs\tHanks\tCutter\tBoston Daily Advertiser\tChicago Times\n",
      "1865 Iwill\tProvidences\tDETROIT\tAbraham Lincoln\tLaw\n"
     ]
    }
   ],
   "source": [
    "for year in range(1846,1866):\n",
    "    pmi_year = get_PMI(year)\n",
    "    pmi_year_filtered = {name:pmi for name,pmi in pmi_year.items() if name in top1k}\n",
    "    top_names = sorted(pmi_year_filtered,key=pmi_year_filtered.get,reverse=True)[:5]\n",
    "    print(year,'\\t'.join(name.split('_')[0] for name in top_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are honestly not so great -- lots of typos and capitalization issues. \n",
    "\n",
    "There are also a lot of mentions of other newspapers, which might make sense, depending on when those newspapers ran, and whether Liberator frequently borrowed from them.\n",
    "\n",
    "Future work on this data could play with smoothing, try TF-IDF instead of PMI, or work with the count of unique stories or issues in which each name appears, rather than the raw counts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
