{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Named entity recognition\n",
    "\n",
    "- Jacob Eisenstein\n",
    "- For Georgia Tech CS8803-CSS, Fall 2017\n",
    "\n",
    "In this project, you'll use Stanford's CoreNLP tagger to tag names of people, places, and organizations in the abolitionist newspaper The Liberator.\n",
    "\n",
    "You can download the software here:\n",
    "\n",
    "https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "\n",
    "Next, unzip it:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 28,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  stanford-ner-2017-06-09.zip\n",
<<<<<<< HEAD
      "   creating: stanford-ner-2017-06-09/\n",
      "  inflating: stanford-ner-2017-06-09/README.txt  \n",
      "  inflating: stanford-ner-2017-06-09/stanford-ner-3.8.0.jar  \n",
      "  inflating: stanford-ner-2017-06-09/ner-gui.bat  \n",
      "  inflating: stanford-ner-2017-06-09/build.xml  \n",
      "  inflating: stanford-ner-2017-06-09/stanford-ner-3.8.0-sources.jar  \n",
      "  inflating: stanford-ner-2017-06-09/stanford-ner.jar  \n",
      "  inflating: stanford-ner-2017-06-09/sample-conll-file.txt  \n",
      "  inflating: stanford-ner-2017-06-09/sample.ner.txt  \n",
      "   creating: stanford-ner-2017-06-09/lib/\n",
      "  inflating: stanford-ner-2017-06-09/lib/joda-time.jar  \n",
      "  inflating: stanford-ner-2017-06-09/lib/stanford-ner-resources.jar  \n",
      "  inflating: stanford-ner-2017-06-09/lib/jollyday-0.4.9.jar  \n",
      "  inflating: stanford-ner-2017-06-09/ner-gui.command  \n",
      "  inflating: stanford-ner-2017-06-09/ner.sh  \n",
      "  inflating: stanford-ner-2017-06-09/stanford-ner-3.8.0-javadoc.jar  \n",
      "  inflating: stanford-ner-2017-06-09/NERDemo.java  \n",
      "  inflating: stanford-ner-2017-06-09/ner.bat  \n",
      "   creating: stanford-ner-2017-06-09/classifiers/\n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.conll.4class.distsim.prop  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.muc.7class.distsim.prop  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.prop  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/example.serialized.ncc.prop  \n",
      "  inflating: stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2017-06-09/sample.txt  \n",
      "  inflating: stanford-ner-2017-06-09/sample-w-time.txt  \n",
      "  inflating: stanford-ner-2017-06-09/ner-gui.sh  \n",
      "  inflating: stanford-ner-2017-06-09/LICENSE.txt  \n"
=======
      "replace stanford-ner-2017-06-09/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
>>>>>>> upstream/master
     ]
    }
   ],
   "source": [
    "! unzip stanford-ner-2017-06-09.zip"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 30,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from glob import glob\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a tagger object. The first argument is the location of the model file, the second argument is the location of the jar file. Both should have been extracted from the zipfile you downloaded."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 31,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = StanfordNERTagger('stanford-ner-2017-06-09/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "                           path_to_jar='stanford-ner-2017-06-09/stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it. The input is a sequence of tokens. Here we'll just use string split for tokenization."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 32,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = 'Colonel Mustard was in Druid Hills , with the President of the Coca Cola Corporation .'.split()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 33,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colonel', 'O'),\n",
       " ('Mustard', 'PERSON'),\n",
       " ('was', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Druid', 'LOCATION'),\n",
       " ('Hills', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('President', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Coca', 'ORGANIZATION'),\n",
       " ('Cola', 'ORGANIZATION'),\n",
       " ('Corporation', 'ORGANIZATION'),\n",
       " ('.', 'O')]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 33,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a labeling of each token. The tag 'O' means 'outside' of any entity name.\n",
    "\n",
    "Here is a simple function that extracts names from this output."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 34,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entities(tagger_output):\n",
    "    current_entity = []\n",
    "    entities = []\n",
    "    for token,tag in tagger_output:\n",
    "        if tag != 'O':\n",
    "            current_entity.append((token,tag))\n",
    "        else:\n",
    "            if current_entity != []:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "    return ['%s_%s'%(' '.join([tok for tok,tag in entity]),entity[0][1]) for entity in entities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the function."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 35,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mustard_PERSON',\n",
       " 'Druid Hills_LOCATION',\n",
       " 'Coca Cola Corporation_ORGANIZATION']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 35,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a harder one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_example = 'I told Lucia Coca Cola was bad for her teeth .'.split()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 36,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'O'),\n",
       " ('told', 'O'),\n",
       " ('Lucia', 'ORGANIZATION'),\n",
       " ('Coca', 'ORGANIZATION'),\n",
       " ('Cola', 'ORGANIZATION'),\n",
       " ('was', 'O'),\n",
       " ('bad', 'O'),\n",
       " ('for', 'O'),\n",
       " ('her', 'O'),\n",
       " ('teeth', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 36,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(hard_example)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 37,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucia Coca Cola_ORGANIZATION']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
=======
     "execution_count": 37,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(hard_example))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 42,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with_complementizer = 'I told Taha that Coca Cola was bad for her teeth .'.split()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 43,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taha_PERSON', 'Coca Cola_ORGANIZATION']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 43,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagger.tag(with_complementizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is why you should use complementizers when you write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging full documents\n",
    "\n",
    "To do better word segmentation, make sure you have downloaded the `punkt` tokenization model from nltk."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 44,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/istewart/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
<<<<<<< HEAD
     "execution_count": 17,
=======
     "execution_count": 44,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try tagging a document from The Liberator.\n",
    "\n",
    "Link or copy this directory in from Lab 7 if necessary."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link './liberator-stories': File exists\r\n"
     ]
    }
   ],
>>>>>>> upstream/master
   "source": [
    "! ln -s ../lab7/liberator-stories/"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 46,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'liberator-stories/Issue of April 01, 1853/story006.txt'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 47,
   "metadata": {},
>>>>>>> upstream/master
   "outputs": [],
   "source": [
    "tagged_lines = []\n",
    "with open(filename) as fin:\n",
    "    for line in fin:\n",
    "        tagged_lines.append(tagger.tag(word_tokenize(line)))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 48,
>>>>>>> upstream/master
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Southern', 'MISC'), ('slaveholders', 'O'), ('have', 'O'), ('a', 'O'), ('passion', 'O'), ('for', 'O'), ('mischiefframed', 'O'), ('into', 'O'), ('law', 'O'), (',', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_lines[0][:10])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 49,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Southern_MISC',\n",
       " 'North_LOCATION',\n",
       " 'Illinois_LOCATION',\n",
       " 'Virginia_LOCATION',\n",
       " 'Old Dominion_MISC',\n",
       " 'Illinoisan_LOCATION',\n",
       " 'Virginia_LOCATION',\n",
       " 'Illinois_LOCATION',\n",
       " 'Northern_ORGANIZATION',\n",
       " 'question-In_MISC',\n",
       " 'Democracy_ORGANIZATION',\n",
       " 'Commonwealth_ORGANIZATION']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 22,
=======
     "execution_count": 49,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(tagged_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn**: Get a story from today's news, copy it into the variable below, and extract the named entities. Skim the first few lines of the story yourself to see if it's correct. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 52,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "your_story = \"\"\"\n",
<<<<<<< HEAD
    "• President Xi Jinping’s extraordinarily long opening speech set the tone for China’s weeklong Communist Party congress.\n",
    "\n",
    "He declared a “new era” and stressed the country’s “great power,” in comments that effectively claimed a stature as significant to today’s China as Mao Zedong and Deng Xiaoping held in theirs. Here are five takeaways from his marathon speech.\n",
    "\n",
    "Mr. Xi’s rise has been marked by rekindled enthusiasm for traditional culture. One piece of evidence: His embrace of the Confucian philosopher Wang Yangming prompted the city of Guiynag to build a theme park, construct a museum and even commission a robot to bring the philosopher to life.\n",
    "U.S. State Department files showed that American officials looked on silently during Indonesia’s anti-Communist bloodbath in the mid-60s — and at times even applauded the forces behind the killings of at least half a million people.\n",
    "\n",
    "Cold War attitudes may have motivated U.S. diplomats to simply watch as mass extrajudicial executions spread beyond suspected Communists to target ethnic Chinese, students and union members.\n",
    "\n",
    "Secretary of State Rex Tillerson was harsh in condemning reported atrocities against Rohingya Muslims in Myanmar’s border area with Bangladesh. Mr. Tillerson demanded access to the strife-hit region to allow a “full accounting” of the circumstances.\n",
    "\n",
    "Since Sunday, as many as 15,000 Rohingya have crossed into Bangladesh, a U.N. spokesman said, where the refugees are waiting to enter already overcrowded camps.\n",
=======
    "A new video of what would appear to be one of Apple’s “Project Titan” self-driving cars was posted to Twitter last night, and it looks much different than it did the last time we saw it. The car appears to be outfitted with standard third-party sensors and hardware, including (count ‘em) six Velodyne-made LIDAR sensors, several radar units, and a number of cameras — all encased in Apple-esque white plastic.\n",
    "\n",
    "The video was captured by someone who knows his stuff about autonomous vehicles: MacCallister Higgins, co-founder of self-driving startup Voyage (that just launched its own pilot ride-hailing project in a San Jose retirement community). Higgins jokingly referred to the \n",
    "\n",
    "Indeed, when you compare Apple’s car with the latest iteration of Waymo’s self-driving minivan, the differences are striking. While Waymo has minimized and streamlined its sensors so they conform nicely with the vehicle’s body, Apple’s are perched on the vehicle’s roof like an ugly cargo carrier.\n",
    "\n",
    "When I asked Higgins if he caught a look at the compute stack, he replied that it was likely located on the roof with the sensors. That would be a departure from other self-driving car operators, who typically load their high-powered GPUs in the vehicles’ spacious trunks.\n",
    "\n",
    "Earlier this year, Apple caused a stir when it applied for and received a permit to test autonomous vehicles on public roads in California. We do know, from various reports that Apple has ditched its ambitions to build an entirely new vehicle from scratch and has instead shifted focused to building autonomous software it could develop for existing carmakers. Last July, CEO Tim Cook confirmed in an interview that the iPhone maker is currently “focusing on autonomous systems” — rather than, say, a car stamped with the Apple logo — and that this could be used for many different purposes.\n",
    "\n",
    "\n",
    "\n",
>>>>>>> upstream/master
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['Communist Party_ORGANIZATION',\n",
       " 'China_LOCATION',\n",
       " 'Mao Zedong_PERSON',\n",
       " 'Deng Xiaoping_PERSON',\n",
       " 'Confucian_MISC',\n",
       " 'Wang Yangming_PERSON',\n",
       " 'Guiynag_LOCATION',\n",
       " 'U.S. State Department_ORGANIZATION',\n",
       " 'American_MISC',\n",
       " 'Indonesia’s anti-Communist_MISC',\n",
       " 'U.S._LOCATION',\n",
       " 'Communists_MISC',\n",
       " 'Chinese_MISC',\n",
       " 'Rex Tillerson_PERSON',\n",
       " 'Rohingya Muslims_PERSON',\n",
       " 'Bangladesh_LOCATION',\n",
       " 'Tillerson_PERSON',\n",
       " 'Rohingya_MISC',\n",
       " 'Bangladesh_LOCATION',\n",
       " 'U.N._ORGANIZATION']"
=======
       "['Apple_ORGANIZATION',\n",
       " 'Twitter_MISC',\n",
       " 'LIDAR_ORGANIZATION',\n",
       " 'Apple-esque_MISC',\n",
       " 'MacCallister Higgins_PERSON',\n",
       " 'San Jose_LOCATION',\n",
       " 'Higgins_PERSON',\n",
       " 'Apple_ORGANIZATION',\n",
       " 'Waymo_LOCATION',\n",
       " 'Waymo_PERSON',\n",
       " 'Apple_ORGANIZATION',\n",
       " 'Higgins_PERSON',\n",
       " 'GPUs_PERSON',\n",
       " 'Apple_ORGANIZATION',\n",
       " 'California_LOCATION',\n",
       " 'Apple_ORGANIZATION',\n",
       " 'Tim Cook_PERSON',\n",
       " 'Apple_ORGANIZATION']"
>>>>>>> upstream/master
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's my output\n",
    "get_entities(tagger.tag(word_tokenize(your_story)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting entities\n",
    "\n",
    "We can keep count of all these different entities, using a `Counter` object."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 54,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 55,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Commonwealth_ORGANIZATION': 1,\n",
       "         'Democracy_ORGANIZATION': 1,\n",
       "         'Illinois_LOCATION': 2,\n",
       "         'Illinoisan_LOCATION': 1,\n",
       "         'North_LOCATION': 1,\n",
       "         'Northern_ORGANIZATION': 1,\n",
       "         'Old Dominion_MISC': 1,\n",
       "         'Southern_MISC': 1,\n",
       "         'Virginia_LOCATION': 2,\n",
       "         'question-In_MISC': 1})"
      ]
     },
<<<<<<< HEAD
     "execution_count": 26,
=======
     "execution_count": 55,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(get_entities(tagged_lines[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cool thing about counters is that you can add them up, which makes it easy to keep a running count."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 56,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter1 = Counter(get_entities(tagged_lines[0]))\n",
    "counter1 += Counter(get_entities(tagged_lines[0]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 57,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Commonwealth_ORGANIZATION': 2,\n",
       "         'Democracy_ORGANIZATION': 2,\n",
       "         'Illinois_LOCATION': 4,\n",
       "         'Illinoisan_LOCATION': 2,\n",
       "         'North_LOCATION': 2,\n",
       "         'Northern_ORGANIZATION': 2,\n",
       "         'Old Dominion_MISC': 2,\n",
       "         'Southern_MISC': 2,\n",
       "         'Virginia_LOCATION': 4,\n",
       "         'question-In_MISC': 2})"
      ]
     },
<<<<<<< HEAD
     "execution_count": 28,
=======
     "execution_count": 57,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Virginia_LOCATION', 4),\n",
       " ('Illinois_LOCATION', 4),\n",
       " ('Democracy_ORGANIZATION', 2)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter1.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to incrementally build a counter as we process all stories in a single edition.\n",
    "\n",
    "Another useful trick is to build a counter from a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_list = ['a','b','a','a','c','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3, 'b': 2, 'c': 1})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(the_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** \n",
    "\n",
    "- Count the number of times a person is mentioned in your news story.\n",
    "- Count the total number of different person names that are mentioned."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 total person counts\n",
      "6 unique person counts\n",
      "person tags:\n",
      "Deng Xiaoping_PERSON\n",
      "Mao Zedong_PERSON\n",
      "Rex Tillerson_PERSON\n",
      "Rohingya Muslims_PERSON\n",
      "Tillerson_PERSON\n",
      "Wang Yangming_PERSON\n"
     ]
    }
   ],
   "source": [
    "story_tags = get_entities(tagger.tag(word_tokenize(your_story)))\n",
    "tag_to_match = 'PERSON'\n",
    "person_tags = list(filter(lambda x: x.endswith(tag_to_match), story_tags))\n",
    "person_count = len(person_tags)\n",
    "unique_person_count = len(set(person_tags))\n",
    "print('%d total person counts'%(person_count))\n",
    "print('%d unique person counts'%(unique_person_count))\n",
    "print('person tags:\\n%s'%('\\n'.join(sorted(person_tags))))"
=======
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = get_entities(tagger.tag(word_tokenize(your_story)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_tuples = [entity.split('_') for entity in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter([name for \n",
    "                   name,ne_type \n",
    "                   in entity_tuples\n",
    "                   if ne_type=='PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for entity_tuple in entity_tuples:\n",
    "    if entity_tuple[1] == 'PERSON':\n",
    "        counter[entity_tuple[0]] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'GPUs': 1,\n",
       "         'Higgins': 2,\n",
       "         'MacCallister Higgins': 1,\n",
       "         'Tim Cook': 1,\n",
       "         'Waymo': 1})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing entities across multiple texts\n",
    "\n",
    "Now let's compare the named entities that are mentioned in two specific editions."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 77,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edition1 = 'liberator-stories/Issue of November 01, 1850'\n",
    "edition2 = 'liberator-stories/Issue of November 11, 1859'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to compute a running count of entities across the lines and stories of an issue."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": 78,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_counts(directory,show_progress=False):\n",
    "    entity_counts = Counter()\n",
    "    for filename in glob(os.path.join(directory,'story*txt')):\n",
    "        with open (filename) as fin:\n",
    "            if show_progress: \n",
    "                print(filename)\n",
    "            for i,line in enumerate(fin):\n",
    "                if len(line)>10:\n",
    "                    output = tagger.tag(word_tokenize(line))\n",
    "                    entity_counts += Counter(get_entities(output))\n",
    "    return entity_counts"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 79,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberator-stories/Issue of November 01, 1850/story000.txt\n",
<<<<<<< HEAD
      "liberator-stories/Issue of November 01, 1850/story001.txt\n",
      "liberator-stories/Issue of November 01, 1850/story002.txt\n",
      "liberator-stories/Issue of November 01, 1850/story003.txt\n",
      "liberator-stories/Issue of November 01, 1850/story004.txt\n",
      "liberator-stories/Issue of November 01, 1850/story005.txt\n",
      "liberator-stories/Issue of November 01, 1850/story006.txt\n",
      "liberator-stories/Issue of November 01, 1850/story007.txt\n",
      "liberator-stories/Issue of November 01, 1850/story008.txt\n",
      "liberator-stories/Issue of November 01, 1850/story009.txt\n"
=======
      "liberator-stories/Issue of November 01, 1850/story008.txt\n",
      "liberator-stories/Issue of November 01, 1850/story003.txt\n",
      "liberator-stories/Issue of November 01, 1850/story004.txt\n",
      "liberator-stories/Issue of November 01, 1850/story006.txt\n",
      "liberator-stories/Issue of November 01, 1850/story001.txt\n",
      "liberator-stories/Issue of November 01, 1850/story007.txt\n",
      "liberator-stories/Issue of November 01, 1850/story002.txt\n",
      "liberator-stories/Issue of November 01, 1850/story009.txt\n",
      "liberator-stories/Issue of November 01, 1850/story005.txt\n"
>>>>>>> upstream/master
     ]
    }
   ],
   "source": [
    "counts1 = get_entity_counts(edition1,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Massachusetts_LOCATION', 14),\n",
       " ('Constitution_ORGANIZATION', 13),\n",
       " ('United States_LOCATION', 9),\n",
       " ('Senate_ORGANIZATION', 9),\n",
       " ('God_PERSON', 7)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts1.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liberator-stories/Issue of November 11, 1859/story000.txt\n",
      "liberator-stories/Issue of November 11, 1859/story008.txt\n",
      "liberator-stories/Issue of November 11, 1859/story003.txt\n",
      "liberator-stories/Issue of November 11, 1859/story004.txt\n",
      "liberator-stories/Issue of November 11, 1859/story006.txt\n",
      "liberator-stories/Issue of November 11, 1859/story001.txt\n",
      "liberator-stories/Issue of November 11, 1859/story007.txt\n",
      "liberator-stories/Issue of November 11, 1859/story002.txt\n",
      "liberator-stories/Issue of November 11, 1859/story009.txt\n",
      "liberator-stories/Issue of November 11, 1859/story005.txt\n"
     ]
    }
   ],
>>>>>>> upstream/master
   "source": [
    "counts2 = get_entity_counts(edition2,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Massachusetts_LOCATION', 14),\n",
       " ('Constitution_ORGANIZATION', 13),\n",
       " ('United States_LOCATION', 9),\n",
       " ('Senate_ORGANIZATION', 9),\n",
       " ('God_PERSON', 7),\n",
       " ('California_LOCATION', 6),\n",
       " ('Whittier_LOCATION', 6),\n",
       " ('ERRIEN_ORGANIZATION', 6),\n",
       " ('BERRIEN_ORGANIZATION', 6),\n",
       " ('North_LOCATION', 5)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harper_PERSON', 13),\n",
       " ('Brown_PERSON', 12),\n",
       " ('North_LOCATION', 11),\n",
       " ('South_LOCATION', 9),\n",
       " ('Phillips_PERSON', 9),\n",
       " ('Virginia_LOCATION', 8),\n",
       " ('Republican_MISC', 7),\n",
       " ('Seward_PERSON', 6),\n",
       " ('Beecher_PERSON', 4),\n",
       " ('Giddings_ORGANIZATION', 4)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts2.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the John Brown's raid of Harper's Ferry dominates the news in late 1859, even though the NER system mistakenly label \"Harper\" as a person. Another key difference is \"North\" and \"South\" seem to play a bigger role in the 1859 data, which might make sense, as the war in only a year and a half away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Your turn** What are the ten most frequently-mentioned organizations, across **both** newspaper issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Constitution_ORGANIZATION', 14),\n",
       " ('Senate_ORGANIZATION', 9),\n",
       " ('ERRIEN_ORGANIZATION', 6),\n",
       " ('BERRIEN_ORGANIZATION', 6),\n",
       " ('Congress_ORGANIZATION', 6),\n",
       " ('Fugitive Slave Bill_ORGANIZATION', 5),\n",
       " ('Giddings_ORGANIZATION', 4),\n",
       " ('Supreme Court_ORGANIZATION', 4),\n",
       " ('Union_ORGANIZATION', 4),\n",
       " ('Legislature_ORGANIZATION', 3)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-scale comparison\n",
    "\n",
    "Now let's do a large-scale comparison over the years of the dataset. Because the NER system is a little slow, I ran it overnight on our server. You can load in the output as shown:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 83,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tar xzf liberator-nes.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States_LOCATION\n",
      "States_LOCATION\n",
      "SWERED_ORGANIZATION\n",
      "Unioncan_LOCATION\n",
      "States_LOCATION\n",
      "ONSTITUTION_ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "with open('TheLiberator/Issue of April 15, 1859/story001.ne') as fin:\n",
    "    for line in fin:\n",
    "        print (line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** Read this same file into a counter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'States_LOCATION': 3, 'SWERED_ORGANIZATION': 1, 'ONSTITUTION_ORGANIZATION': 1, 'Unioncan_LOCATION': 1})\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "entity_counts = Counter([l.rstrip() for l in open('TheLiberator/Issue of April 15, 1859/story001.ne')])\n",
    "print(entity_counts)"
=======
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "with open('TheLiberator/Issue of April 15, 1859/story001.ne') as fin:\n",
    "    counts = Counter(line.rstrip() for line in fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "with open('TheLiberator/Issue of April 15, 1859/story001.ne') as fin:\n",
    "    counts = Counter()\n",
    "    for line in fin:\n",
    "        counts[line.rstrip()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ONSTITUTION_ORGANIZATION': 1,\n",
       "         'SWERED_ORGANIZATION': 1,\n",
       "         'States_LOCATION': 3,\n",
       "         'Unioncan_LOCATION': 1})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build counters for all stories in a year. The following function should help."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 89,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_files_for_year = lambda year : glob('TheLiberator/Issue*%d/story*.ne'%(year))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 91,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['TheLiberator/Issue of June 25, 1852/story000.ne',\n",
       " 'TheLiberator/Issue of June 25, 1852/story001.ne',\n",
       " 'TheLiberator/Issue of June 25, 1852/story002.ne',\n",
       " 'TheLiberator/Issue of June 25, 1852/story003.ne',\n",
       " 'TheLiberator/Issue of June 25, 1852/story004.ne']"
      ]
     },
     "execution_count": 44,
=======
       "['TheLiberator/Issue of August 05, 1859/story031.ne',\n",
       " 'TheLiberator/Issue of August 05, 1859/story035.ne',\n",
       " 'TheLiberator/Issue of August 05, 1859/story014.ne',\n",
       " 'TheLiberator/Issue of August 05, 1859/story008.ne',\n",
       " 'TheLiberator/Issue of August 05, 1859/story002.ne']"
      ]
     },
     "execution_count": 91,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files_for_year(1859)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn** Implement the following function, which should return a counter of entity names for all stories in a given year. Don't forget the two tricks about Counters that I showed you above."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 92,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_counts_for_year(year):\n",
    "    counts = Counter()\n",
<<<<<<< HEAD
    "    for f in get_files_for_year(year):\n",
    "        f_counts = Counter([l.rstrip() for l in open(f)])\n",
    "        counts += f_counts\n",
=======
    "    for filename in get_files_for_year(year):\n",
    "        with open(filename) as fin:\n",
    "            counts += Counter(line.rstrip() for line in fin)\n",
>>>>>>> upstream/master
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Massachusetts_LOCATION', 150),\n",
       " ('God_PERSON', 136),\n",
       " ('Boston_LOCATION', 127),\n",
       " ('South_LOCATION', 77),\n",
       " ('Brown_PERSON', 76),\n",
       " ('United States_LOCATION', 70),\n",
       " ('Constitution_ORGANIZATION', 68),\n",
       " ('North_LOCATION', 66),\n",
       " ('New York_LOCATION', 62),\n",
       " ('Oregon_LOCATION', 58)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_counts_for_year(1859).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the top entities for every year"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 94,
>>>>>>> upstream/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1846: American God Alliance Rev United States Christian America England Massachusetts Boston\n",
      "1847: God American Mexico Boston United States Christian Union England Douglass South\n",
      "1848: God South North Senate Boston Union Congress American House United States\n",
      "1849: God South Boston American Congress Christian New York North United States Southern\n",
      "1850: God South Boston Webster North Congress United States Massachusetts Union Senate\n",
      "1851: God American Boston America England United States Union Constitution States North\n",
      "1852: God Boston American South Constitution New York America Pierce Washington Parker\n",
      "1853: God Boston Mann American Constitution United States Christian Massachusetts New York England\n",
      "1854: Boston God Congress American South United States Constitution Ohio North States\n",
      "1855: God Union South American North Constitution Boston Massachusetts United States New York\n",
      "1856: Kansas God South Boston North United States Union American New York Massachusetts\n",
      "1857: God South Boston North Kansas Convention American Christian Constitution New York\n",
      "1858: God Massachusetts Boston S.A. Allen Constitution South United States Legislature Union REV\n",
      "1859: Massachusetts God Boston South Brown United States Constitution North New York American\n",
      "1860: God Boston Rev Constitution New York Sumner United States Republican American Parker\n",
      "1861: North God South Union Boston States Massachusetts Constitution Southern New York\n",
      "1862: God South North Union Boston Massachusetts Washington States Congress United States\n",
      "1863: God North South Boston England United States Hinna America American Union\n",
      "1864: Lincoln North God Union South Congress American Boston United States England\n",
      "1865: South God United States North States Congress Southern Union Washington American\n"
=======
      "1846: American God Alliance Rev United States\n",
      "1847: God American Mexico Boston United States\n",
      "1848: God South North Senate Boston\n",
      "1849: God South Boston American Congress\n",
      "1850: God South Boston Webster North\n",
      "1851: God American Boston America England\n",
      "1852: God Boston American South Constitution\n",
      "1853: God Boston Mann American Constitution\n",
      "1854: Boston God Congress American South\n",
      "1855: God Union South American Constitution\n",
      "1856: Kansas God South Boston North\n",
      "1857: God South Boston North Kansas\n",
      "1858: God Massachusetts Boston S.A. Allen Constitution\n",
      "1859: Massachusetts God Boston South Brown\n",
      "1860: God Boston Rev Constitution New York\n",
      "1861: North God South Union Boston\n",
      "1862: God South North Union Boston\n",
      "1863: God North South Boston England\n",
      "1864: Lincoln North God Union South\n",
      "1865: South God United States North States\n"
>>>>>>> upstream/master
     ]
    }
   ],
   "source": [
    "for year in range(1846,1866):\n",
    "    print(year,end=': ')\n",
    "    print(' '.join([name.split('_')[0] \n",
    "                    for name,count \n",
    "                    in get_entity_counts_for_year(year).most_common(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise mutual information \n",
    "\n",
    "The top named appear to be dominated by a few recurring items: God, American, South, etc.\n",
    "\n",
    "Remember that we addressed this problem before by using pointwise mutual information (PMI). As a reminder, here is the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{PMI}(i,j) = \\log \\frac{P(i,j)}{P(i)P(j)} = \\log \\frac{P(i \\mid j) P(j)}{P(i) P(j)} = \\log P(i \\mid j) - \\log P(i)\n",
    "\\end{equation}\n",
    "\n",
    "We can compute this directly from the Counter objects. First let's compute the bottom term, $\\log P(i)$, which is the probability of each entity name, over all years in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_counts = Counter()\n",
    "for year in range(1846,1866):\n",
    "    total_counts += get_entity_counts_for_year(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # we need this for log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_pi = {name:np.log(count) for name,count in total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', 7.9069154886785871),\n",
       " ('South_LOCATION', 7.4442486494967053),\n",
       " ('Boston_LOCATION', 7.4193805829186923),\n",
       " ('North_LOCATION', 7.2640301428995295),\n",
       " ('American_MISC', 7.1808311990445555)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,log_pi[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the log counts. Note that they are positive -- this means that they can't be log probabilities! $(p(x) <= 1 \\Leftrightarrow \\log p(x) <= 0)$. \n",
    "\n",
    "We'll fix this by subtracting $\\log N$, where $N$ is the sum of all counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_log_N = np.log(sum(total_counts.values()))\n",
    "log_pi = {name:np.log(count) - tot_log_N\n",
    "          for name,count in total_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -3.9701877038264808),\n",
       " ('South_LOCATION', -4.4328545430083626),\n",
       " ('Boston_LOCATION', -4.4577226095863756),\n",
       " ('North_LOCATION', -4.6130730496055383),\n",
       " ('American_MISC', -4.6962719934605124)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,log_pi[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000010483"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exps of log probabilities should sum to one\n",
    "sum(np.exp(val) for val in log_pi.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! \n",
    "\n",
    "Now, to compute $\\log P(i \\mid j)$, you just need to do the same operation, but with the counter for each specific year.\n",
    "\n",
    "**Your turn**: fill in the function below, which should return a dict of names and log probabilites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_log_pij(year):\n",
    "    counts = get_entity_counts_for_year(year)\n",
    "    # your code here\n",
    "    return #something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -4.2038142706300592),\n",
       " ('South_LOCATION', -4.7726637345124274),\n",
       " ('Boston_LOCATION', -4.2722820699075204),\n",
       " ('North_LOCATION', -4.9268144143396864),\n",
       " ('American_MISC', -5.0560261458196925)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desired output\n",
    "[(name,get_log_pij(1859)[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999992628"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the probabilities still sum to one\n",
    "sum(np.exp(val) for val in get_log_pij(1859).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the PMI. Note that we need only compute PMI for names the appear in the year; it's undefined $(\\log 0)$ for other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_PMI(year):\n",
    "    log_pij = get_log_pij(year)\n",
    "    pmi = {name:log_pij_name- log_pi[name] \n",
    "           for name,log_pij_name \n",
    "           in log_pij.items()}           \n",
    "    return pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('God_PERSON', -0.22630052671150569),\n",
       " ('South_LOCATION', -0.32690578666815728),\n",
       " ('Boston_LOCATION', 0.19328371713988091),\n",
       " ('North_LOCATION', -0.2987034873696075),\n",
       " ('American_MISC', -0.34265971899987946)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name,get_PMI(1859)[name]) for name,count in total_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top names by PMI per year\n",
    "\n",
    "Now we'll call your function to get the top names by PMI for each year. \n",
    "\n",
    "We'll focus on names among the 500 most common overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top1k = [name for name,count in tot_counts.most_common(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846 Stephen C. Phillips\tNational Anti-SlaveryStandard\tBingham\tRio Grande\tHabeas Corpus\n",
      "1847 HORN\tDouglass\tFrederick\tRichmond Enquirer\tEssex\n",
      "1848 Berrien\tCorwin\tSoutherner\tRio Grande\tHale\n",
      "1849 Cooke\tAssembly\tSouthern\tWashington Union\tEssex\n",
      "1850 James Hamlet\tSlave Trade Bill\tLegislature of the State\tHaynau\tBerrien\n",
      "1851 Fugitive SlaveBill\tThis Committee\tDuncan\tFugitive Slave\tFugitive Slave Law\n",
      "1852 Hungary\tFugitive SlaveLaw\tSupreme Court of the UnitedStates\tEssex\tN.Y. Express\n",
      "1853 Robespierre\tHORACE MANN\tHaynau\tHorace Mann\tIdo\n",
      "1854 Atchinson\tSurrey\tLikethe\tBoston Daily Advertiser\tCourt House\n",
      "1855 OUGLAS\tRichmond Enquirer\tFugitive SlaveBill\tSlave Bill\tBurns\n",
      "1856 North Fifth\tChicago Press\tFrederick ( Md\tBuffalo Express\tThisquestion\n",
      "1857 Charles F. Adams\tILLIAM LLERY HANNING\tStephens\tLikethe\tState of Virginia\n",
      "1858 Abolitionistsof\tState Constitutions\tSlaverywill\tGospel of Christ\tCharleston Courier\n",
      "1859 Ifit\tBrewster\tWENDELLPHILLIPS\tArsenal\tJohn Brown\n",
      "1860 Statelaws\tWILLIAM ELLERY CHANNING\tSanborn\tAbolition\tWENDELLPHILLIPS\n",
      "1861 Northerner\tNorthernpeople\tWilliam H.Seward\tHour\tLedyard\n",
      "1862 EWING\tChandler\tPotomac\tRepublicanpress\tSecretary of War\n",
      "1863 OUGLAS\tDAVIS\tNew York Journal of Commerce\tBingham\tAVIS\n",
      "1864 Messrs\tHanks\tCutter\tBoston Daily Advertiser\tChicago Times\n",
      "1865 Iwill\tProvidences\tDETROIT\tAbraham Lincoln\tLaw\n"
     ]
    }
   ],
   "source": [
    "for year in range(1846,1866):\n",
    "    pmi_year = get_PMI(year)\n",
    "    pmi_year_filtered = {name:pmi for name,pmi in pmi_year.items() if name in top1k}\n",
    "    top_names = sorted(pmi_year_filtered,key=pmi_year_filtered.get,reverse=True)[:5]\n",
    "    print(year,'\\t'.join(name.split('_')[0] for name in top_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are honestly not so great -- lots of typos and capitalization issues. \n",
    "\n",
    "There are also a lot of mentions of other newspapers, which might make sense, depending on when those newspapers ran, and whether Liberator frequently borrowed from them.\n",
    "\n",
    "Future work on this data could play with smoothing, try TF-IDF instead of PMI, or work with the count of unique stories or issues in which each name appears, rather than the raw counts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
